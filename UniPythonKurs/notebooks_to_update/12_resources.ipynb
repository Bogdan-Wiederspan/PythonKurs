{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36432211-93be-45dc-9692-b6caa904a07e",
   "metadata": {},
   "source": [
    "*Authors:* "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b56ad04-9fd6-4929-b518-e5d80a36113b",
   "metadata": {},
   "source": [
    "# Lesson 12: Efficient resource usage\n",
    "\n",
    "*Goals*: understand how a task (e.g. a program) is executed depending on the syntax used and become aware of the resource consumption.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5224533-1744-41da-b310-d2e628f9fffc",
   "metadata": {},
   "source": [
    "There are generally two kinds of resources that limit any use case:\n",
    "**computing power (e.g. available CPU)** and **Memory**.\n",
    "\n",
    "Both influence the usual metric of interest: **time**, or to be more precise: **walltime** (= the time in real life that passes while a software executes a task).\n",
    "\n",
    "The general relation is easily comparable with a worker digging a hole:\n",
    " * A task is completed faster, if done by a stronger worker (\"faster\" CPU-Core)\n",
    " * A task may be completed faster, if done simultaneously by many workers (more CPU-Cores)\n",
    " * A larger task may be completed if there is more space to do so per step  (more memory)\n",
    " \n",
    " Some tasks primarily require a specific resource (so only rely on CPU or memory), while most others can be balanced to make the most of all available resources. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b89434-90e1-4fd3-8ac5-977e6f8587d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enfore styleguide (see lesson 11)\n",
    "%load_ext pycodestyle_magic\n",
    "%pycodestyle_on"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acb4e1a-f5ac-4c28-96c6-18489efddf67",
   "metadata": {},
   "source": [
    "## Measuring resource consumption:\n",
    "### Time:\n",
    "The simplest way of measuring runtime is by computing the difference between two timestamps with the package ```time```. Think of this as writing down the time when you start executing a task, doing the task, and then writing down the time at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e84626-6e61-4518-83f5-0f4f16348682",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "my_data = np.arange(10)\n",
    "\n",
    "# Start the clock\n",
    "wall_start_time = time.time()\n",
    "\n",
    "# This is the task we want to measure\n",
    "for _ in range(10):\n",
    "    my_data = np.sqrt(my_data*2)\n",
    "    time.sleep(.15)  # wait 150 ms\n",
    "\n",
    "# Record the passed time\n",
    "wall_time = time.time() - wall_start_time\n",
    "\n",
    "print(\"This took\", wall_time, \"seconds in real life.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170fa988-a91d-4172-ad8f-def6a748b5d8",
   "metadata": {},
   "source": [
    "In some cases, especially for parallel applications, it is also important to know how much time the actual computation required (CPU-time).\n",
    "\n",
    "Walltime not caused by the CPU might be due to reading and writing of data, waiting for input from the user or another process, or simply by the fact that other processes are running on the same CPU and your program has to wait to be scheduled for CPU operations.\n",
    "\n",
    "Let's have a look at the previous example from this perspective:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab9b92a-b58f-4373-9f62-fb12ca9b31fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "my_data = np.arange(10)\n",
    "\n",
    "wall_start_time = time.time()\n",
    "cpu_start_time = time.process_time()\n",
    "\n",
    "for _ in range(10):\n",
    "    my_data = np.sqrt(my_data*2)\n",
    "    time.sleep(.15)  # wait 150 ms\n",
    "\n",
    "wall_time = time.time() - wall_start_time\n",
    "cpu_time = time.process_time() - cpu_start_time\n",
    "\n",
    "print(\"This took\", wall_time, \"seconds in real live.\")\n",
    "print(\"This consumed\", cpu_time, \"seconds of cpu-time.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6954f0-e117-45d3-b866-69a911797560",
   "metadata": {},
   "source": [
    "We see that it still needs approximately the same time to finish, although the actual computation could be done in a much shorter time. The obvious reason here is the `sleep()` routine, which artificially pauses the execution.\n",
    "Reasons in real life examples are much harder to identify. Yet this is what you have to do, to optimize your programs. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a335d59d-81ca-4e69-be5a-6def10ec8a03",
   "metadata": {},
   "source": [
    "### Memory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fd2f77-e0e4-45e2-9c8f-b9012c6ec605",
   "metadata": {},
   "source": [
    "Now let's have a look at memory consumption.\n",
    "Every object in Python (e.g. an array) requires memory to be stored. We can check an object's memory consumption with the package ``sys``. For NumPy arrays we use the built-in function ```nbytes```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de5ac6d-f213-48b0-9570-d98747ded29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "print(sys.getsizeof(0))  # integer\n",
    "print(sys.getsizeof(0.0))  # float"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24acfa1-3eb1-4b31-87bd-f5aa15959a7a",
   "metadata": {},
   "source": [
    "In most programming languages, each primitve data type has a fixed size. For Integers that means there is a minimum and maximum that can be represented. In Python 3 this is not true for integers, which can dynamically grow in size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78beb843-e83c-4723-814d-38df92a560aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sys.getsizeof(0))\n",
    "print(sys.getsizeof(1))\n",
    "print(sys.getsizeof(1000000000))\n",
    "print(sys.getsizeof(10000000000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe733cfb-cfb3-41ff-9d4a-5801735f1ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "myint = 0\n",
    "print(sys.getsizeof(myint))\n",
    "myint += 100\n",
    "print(sys.getsizeof(myint))\n",
    "myint += 10000000000\n",
    "print(sys.getsizeof(myint))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee87984-e078-489a-9c98-785df2eae6b0",
   "metadata": {},
   "source": [
    "Beware: `sys.getsizeof` returns the size of the object, but not necessarily the sum of the objects it references (like the contents of a list):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c6ab38-22b5-4e6d-b475-dbd23a7fe218",
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist = list(range(1000))\n",
    "print(sys.getsizeof(mylist))\n",
    "size = 0\n",
    "for i in mylist:\n",
    "    size += sys.getsizeof(i)\n",
    "print(size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0345e900-e2ba-4b4f-a0a2-d6c7bf7c450f",
   "metadata": {},
   "source": [
    "In general, measuring the size of an object is not trivial and a priory not a well-defined task:\n",
    "- Which members of a object do you count?\n",
    "- In the example below, the reference to the next, which includes a reference to the next, ... and even has a cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91a66d3-6aeb-4be8-a0ce-c3453b38919a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, nxt, content):\n",
    "        self.next = nxt\n",
    "        self.content = content\n",
    "\n",
    "    def print_list(self):\n",
    "        print(self.content)\n",
    "        node = self.next\n",
    "        while node != self:\n",
    "            print(node.content)\n",
    "            node = node.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e316cbb3-0f67-413b-b24c-e8c55026e92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_node = Node(None, \"A\")\n",
    "sys.getsizeof(single_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca449b8-6d40-43c2-897f-23b87f10f61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a cyclic list\n",
    "last_node = Node(None, \"D\")\n",
    "clist = Node(last_node, \"C\")\n",
    "clist = Node(clist, \"B\")\n",
    "clist = Node(clist, \"A\")\n",
    "last_node.next = clist\n",
    "\n",
    "clist.print_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d720e3-c677-42fe-b4ab-21577f0eceeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.getsizeof(clist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c619b23-c667-4052-b0d1-8a8a20b1c1b3",
   "metadata": {},
   "source": [
    "Numpy arrays, in constrast to python lists, have a fixed-size data type that can be controlled precisely. The postfix indicates the size in bit (8 bits = 1 byte):\n",
    "- 32 bit = 4 bytes (for floats known as single precision)\n",
    "- 64 bit = 8 bytes (for floats known as double precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e981766d-59b2-4053-9ae1-207a8a291e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_data1 = np.zeros(100)  # type implicitly inferred\n",
    "np_data2 = np.zeros(100, dtype=np.int64)\n",
    "print(np_data1.dtype, np_data1.nbytes)\n",
    "print(np_data2.dtype, np_data2.nbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f2c7ae-5978-4bfb-b925-068d27b14586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can even use less precise types if we want to:\n",
    "np_data1 = np.zeros(100, dtype=np.float32)\n",
    "np_data2 = np.zeros(100, dtype=np.int32)\n",
    "print(np_data1.dtype, np_data1.nbytes)\n",
    "print(np_data2.dtype, np_data2.nbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b408f29-f1f0-423c-b229-e0c9514a6be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_data1 = np.zeros(100, dtype=np.float16)\n",
    "np_data2 = np.zeros(100, dtype=np.int16)\n",
    "print(np_data1.dtype, np_data1.nbytes)\n",
    "print(np_data2.dtype, np_data2.nbytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4691a3c-94ec-44d3-acb8-ac2d646bbdb1",
   "metadata": {},
   "source": [
    "A computer's RAM memory limits us in how many and how large objects our program can use during its execution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe6a37a-b640-415d-a13b-21ed8fe3d805",
   "metadata": {},
   "source": [
    "## Improve memory usage\n",
    "### Ranges\n",
    "\n",
    "In some cases, we do not need actual data but rather a regular sequence of values, e.g. to loop over.\n",
    "This is where you should use a range() that always has the same small memory footprint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d1acff-c118-4ebd-bec5-d230ee7ba750",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "print(sys.getsizeof(range(5)))\n",
    "print(sys.getsizeof(range(5000)))\n",
    "\n",
    "for current_value in range(8, 14, 2):\n",
    "    print(\"Current value is:\", current_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1b7bd9-0069-4b36-88b5-e2bcebd72d35",
   "metadata": {},
   "source": [
    "Check the documentation and learn what the parameters of range() mean and how you can control the sequence:\n",
    "https://docs.python.org/3.9/library/functions.html#func-range"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4072b73-6706-4870-b870-0a99f7bd2773",
   "metadata": {},
   "source": [
    "### Contiguos memory order\n",
    "\n",
    "When data is stored into memory, it will be written as a linear sequence of values and is read the same way. \n",
    "If you think of a 2D-array, in Fortan logic, that means every column is put there one after another. C logic is exactly the other way around, meaning every row is put there one after another.\n",
    "When you access this data, it is makes a huge difference in speed if you read the values from memory in the same sequence they were stored in, or if you have to skip around to get the next value.\n",
    "Numpy uses C logic by default. \n",
    "\n",
    "Let's have an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3e4082-77bb-4404-b77d-bbd1028864f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "size = 2000\n",
    "my_data = np.random.rand(size, size)\n",
    "\n",
    "# mean value of columns:\n",
    "time_columns_start = time.time()\n",
    "for _ in range(100):  # repeat several times\n",
    "    my_data.mean(axis=0)\n",
    "time_columns = time.time() - time_columns_start\n",
    "\n",
    "# mean value of rows:\n",
    "time_rows_start = time.time()\n",
    "for _ in range(100):   # repeat several times\n",
    "    my_data.mean(axis=1)\n",
    "time_rows = time.time() - time_rows_start\n",
    "\n",
    "print(\"By rows:\", time_rows)\n",
    "print(\"By columns:\", time_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c837aba3-6bcb-4ece-8310-72cae15f5edd",
   "metadata": {},
   "source": [
    "The difference here of ~20% does not seem that much, but you can easily imagine more complex examples than computing a mean or examples that require recurring passes over the data where this effect would be even more prominent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57002f1-e93d-43a1-a7a9-aec11cf584e1",
   "metadata": {},
   "source": [
    "## Caching\n",
    "\n",
    "For some problems the concept of *caching* (sometimes called *memoization*) is useful: Store the result of a computation for a given input, such that you can reuse it instead of computing it again. One could build a solution with a dictionary, but Python already has tools included:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af12cd8-d1fd-4818-ab41-2ace2552216b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fibonacci(n):\n",
    "    if n <= 1:\n",
    "        return n\n",
    "    return fibonacci(n-1) + fibonacci(n-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104731d9-b828-4f53-aea2-96d13b289874",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "print(fibonacci(28))\n",
    "print(\"Time:\", time.time() - time_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6523a0d2-c5af-4331-8356-285b7b5e364a",
   "metadata": {},
   "source": [
    "We can use the decorator `functools.cache` to automatically get caching: for each `n` for which we have computed the result already, it does not need to be recomputed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348886fd-6e60-4f0d-ae1b-45728ffe84b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "\n",
    "@functools.cache\n",
    "def fibonacci(n):\n",
    "    if n <= 1:\n",
    "        return n\n",
    "    return fibonacci(n-1) + fibonacci(n-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6769518-9bff-4d63-b4f5-11009f29aebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "print(fibonacci(28))\n",
    "print(\"Time:\", time.time() - time_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aeda60b-11d8-4426-809b-e6d804d91d55",
   "metadata": {},
   "source": [
    "If you cannot afford storing the results for all parameters, it might be better to [use a `lru_cache`](https://docs.python.org/3/library/functools.html#functools.lru_cache) that discards the least recently used elements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba29457-a345-45ec-a18c-bd76f7db56b6",
   "metadata": {},
   "source": [
    "## Compiler vs. Interpreter\n",
    "\n",
    "Every code you write in Python or any other compute language is by itself just text. \n",
    "For a computer to execute your code, it needs to be converted to byte-code. The two concepts of doing this is either via a compiler or via an interpreter. Both do the same job, but with a different strategy because they have different purposes.\n",
    "Research online what exactly this difference is and find an argument, why code run by an interpreter will always be slower than code run after being compiled. \n",
    " * Answer: Interpreter compiles and immediately executes line by line. It only considers what is needed to execute this line and ignores all other context. The purpose is to execute one command given by the user, (e.g. via a command line interpreter like BASH) to do one thing or so-called \"scripts\" that are a collection of things to do. \n",
    " A Compiler reads the entire code and converts it as total block, hence is able to optimize it for execution.\n",
    "\n",
    "Python utilizes an interpreter. This is why you can type and immediately run code in this notebook ;-).\n",
    "This feature is also the most crucial bottleneck in performance of python programs. This is why most concepts for increasing speed are all about bypassing the interpreter.\n",
    "\n",
    "### Just-In-Time Compiler (JIT):\n",
    "The package \"numba\" brings a JIT to the table that we can use to compile a block of code before it is used. This block will be optimized during the compilation, so it should run faster as if read by the interpreter.\n",
    "This makes sense to do for blocks that do the largest part of a program's work, e.g. a loop that does the same thing over many iterations. \n",
    "\n",
    "Let's have a look at a tiny example that computes the value for Pi by sampling random numbers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e397702c-9fc0-46a0-b61f-4606772cb0f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_pi(n_rolls):\n",
    "    n_hits = 0\n",
    "    for _ in range(n_rolls):\n",
    "        x_value = np.random.rand()\n",
    "        y_value = np.random.rand()\n",
    "        radius = (x_value**2 + y_value**2)**0.5\n",
    "        if radius <= 1:\n",
    "            n_hits += 1\n",
    "    pi_approx = 4*n_hits/n_rolls\n",
    "    return pi_approx\n",
    "\n",
    "\n",
    "def time_run(n_rolls):\n",
    "    wall_start_time = time.time()\n",
    "    pi_result = compute_pi(n_rolls)\n",
    "    wall_time = time.time() - wall_start_time\n",
    "    print(\"This took\", wall_time, \"seconds. Pi is:\", pi_result)\n",
    "\n",
    "\n",
    "time_run(100000)\n",
    "time_run(1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c0cf66-fd25-40ba-b837-22520b215a18",
   "metadata": {},
   "source": [
    "This example does exactly what you would expect: \n",
    " * The more samples you tell it to perform, the more precise it will approximate the correct value for Pi.\n",
    " * If you increase the amount of samples by 10x, it needs 10 times as long to finish. \n",
    " \n",
    " Now we will use the JIT to compile the function `compute_pi()` which we can do by just writing a so-called \"decorator\" in front of the function.\n",
    " The first time this function is needed by our program, it will be compiled first and afterwards the compiled version is executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73e7c7b-51a9-4bce-91a5-a6d633fe7fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from numba import njit\n",
    "\n",
    "\n",
    "@njit\n",
    "def compute_pi(n_rolls):\n",
    "    n_hits = 0\n",
    "    for _ in range(n_rolls):\n",
    "        x_value = np.random.rand()\n",
    "        y_value = np.random.rand()\n",
    "        radius = (x_value**2 + y_value**2)**0.5\n",
    "        if radius <= 1:\n",
    "            n_hits += 1\n",
    "    pi_approx = 4*n_hits/n_rolls\n",
    "    return pi_approx\n",
    "\n",
    "\n",
    "def time_run(n_rolls):\n",
    "    wall_start_time = time.time()\n",
    "    pi_result = compute_pi(n_rolls)\n",
    "    wall_time = time.time() - wall_start_time\n",
    "    print(\"This took\", wall_time, \"seconds. Pi is:\", pi_result)\n",
    "\n",
    "\n",
    "time_run(100000)\n",
    "time_run(100000)\n",
    "time_run(1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd0744e-aefa-4442-b00f-634ff3612bdb",
   "metadata": {},
   "source": [
    "Wow, this is way faster than before ;-) (~100x).\n",
    "\n",
    "But wait: why does it take so much longer when we call the function time_run() the first time? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bbcb45-19f6-4241-b4e5-fdeaddf7e618",
   "metadata": {},
   "source": [
    " ## How to identify bottlenecks in a code.\n",
    " \n",
    " If we want to optimize or just speed up our program, we need to know which part is taking how much time. \n",
    " We can then focus on improving the relevant sections that need the most time to complete. \n",
    " For this we can use so-called profiler. \"cProfile\" is already on-board with any Pyhton distribution, so we can always use it right away. \n",
    " Let's see what information it can give us. \n",
    " \n",
    " We will recycle our example from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6f9ff0-7dd3-410e-b87b-a4f735955d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_pi(n_rolls):\n",
    "    n_hits = 0\n",
    "    for _ in range(n_rolls):\n",
    "        x_value = np.random.rand()\n",
    "        y_value = np.random.rand()\n",
    "        radius = (x_value**2 + y_value**2)**0.5\n",
    "        if radius <= 1:\n",
    "            n_hits += 1\n",
    "    pi_approx = 4*n_hits/n_rolls\n",
    "    return pi_approx\n",
    "\n",
    "\n",
    "cProfile.run('compute_pi(1000000)', sort=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009b76f7-8627-4f9f-9815-88af275aed2e",
   "metadata": {},
   "source": [
    "CProfile tracks which functions were called how many times and how log it took to execute them per call and in sum of all calles.\n",
    "In the output above, we can see, that rolling random numbers is what takes up approx. half of the time.\n",
    "With the other half we cannot yet tell in detail because these are not separate functions that cProfile can distinguish.\n",
    "\n",
    "Let's change that by just splitting up every sub-taks into a function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493b2cbf-fc73-4389-9a74-8031b3c3aba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_radius(x_value, y_value):\n",
    "    xy_radius = (x_value**2 + y_value**2)**0.5\n",
    "    return xy_radius\n",
    "\n",
    "\n",
    "def check_hit(radius):\n",
    "    if radius <= 1:\n",
    "        hit = 1\n",
    "    else:\n",
    "        hit = 0\n",
    "    return hit\n",
    "\n",
    "\n",
    "def compute_pi(n_rolls):\n",
    "    n_hits = 0\n",
    "    for _ in range(n_rolls):\n",
    "        x_value = np.random.rand()\n",
    "        y_value = np.random.rand()\n",
    "        radius = compute_radius(x_value, y_value)\n",
    "        n_hits += check_hit(radius)\n",
    "    pi_approx = 4*n_hits/n_rolls\n",
    "    return pi_approx\n",
    "\n",
    "\n",
    "cProfile.run('compute_pi(1000000)', sort=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65896b8c-a1d2-4588-ae9e-53bcc8a9f857",
   "metadata": {},
   "source": [
    "First, we can see that our program got slower, because the interpreter now has to handle more function calls.\n",
    "This offset of <1 second will become negligible for programs that run longer than a few seconds ;-).\n",
    "\n",
    "Now we can distinguish the time components. Rolling random numbers takes ~38% of the total time, computing the radius ~17%, checking if radius is below 1 takes 8%. The remaining 37% fall to everything else, which is only the for-loop (the one-time computation of pi_approx = 4*n_hits/n_rolls is negligible).\n",
    "\n",
    "Collect ideas where and how you would start to improve this program."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e2829e-8436-4006-b3b3-17c10ab7a132",
   "metadata": {},
   "source": [
    "## Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924fbe45-a360-484e-bebb-620dba09a2a7",
   "metadata": {},
   "source": [
    "### Problem 1\n",
    "Get the total size of the elements contained in the following list and store it in `total_size`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cf8a5e-ead2-44ed-acbb-5e39c67405fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROBLEM (2)\n",
    "import sys  # use a function from the sys module like we did before\n",
    "\n",
    "list_of_floats = [0.94, 1.56, -0.68, 1.03, 0.47, 0.47, -1.09, -1.96, -0.8, 0.5]\n",
    "\n",
    "# SOLUTION\n",
    "total_size = sum(sys.getsizeof(f) for f in list_of_floats)\n",
    "\n",
    "# PROBLEM-TEST\n",
    "total_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d62e604-f02e-4010-a92c-02e84ee5b560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELF-CHECK\n",
    "# should be an integer size and larger that this\n",
    "type(total_size), total_size > 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b058071e-cd74-4551-b79e-4ae2e8568eb8",
   "metadata": {},
   "source": [
    "### Problem 2\n",
    "We want to create a numpy array with three floats (initialized with zeros) like\n",
    "```python\n",
    "array = np.zeros(3)\n",
    "```\n",
    "Store the size in bytes of `array` (= all three elements) in a variable `size_in_bytes`. Calculate the size in bits from this and store it in `size_in_bits`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce495ce-3b96-4083-aaff-5c28adfea81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROBLEM (2)\n",
    "import numpy as np\n",
    "array = np.zeros(3)\n",
    "\n",
    "# SOLUTION\n",
    "size_in_bytes = array.nbytes\n",
    "size_in_bits = size_in_bytes * 8\n",
    "\n",
    "# PROBLEM-TEST\n",
    "size_in_bytes, size_in_bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6123cf-256b-4b60-85a5-a2654c777016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELF-CHECK\n",
    "# these should be filled now\n",
    "size_in_bytes, size_in_bits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f97c29-f9ae-46b5-9d6e-c1fae76a0bbd",
   "metadata": {},
   "source": [
    "### Problem 3\n",
    "Create a variable `array` like before (numpy array with 3 floats), but specify the datatype such that *each entry* needs **2 bytes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56218b92-642a-45f2-9533-2932838f6aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROBLEM (2)\n",
    "import numpy as np\n",
    "\n",
    "# SOLUTION\n",
    "array = np.zeros(3, dtype=np.float16)\n",
    "# PROBLEM-TEST\n",
    "array.size, array.nbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19896a5e-9703-4e37-8b63-4705af57aa4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELF-CHECK\n",
    "# it should contain 3 elements\n",
    "print(\"Number of elements:\", array.size)\n",
    "# this should be the size in bytes of *all* three entries\n",
    "print(\"Size in bytes of all elements:\", array.nbytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2a9887-b9a0-4d41-a243-b7bf82a46006",
   "metadata": {},
   "source": [
    "### Problem 4\n",
    "Which of these statements is true?\n",
    "\n",
    "A) CPU time $\\ge$ wall time  \n",
    "B) CPU time $\\le$ wall time  \n",
    "C) CPU time and wall time are synonyms  \n",
    "D) CPU time is something only system admins need to care about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c730c64-634f-4f27-9486-6bcdcc5602bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROBLEM (2)\n",
    "# store your answer as a string (A/B/C/D) in a variable named x\n",
    "# SOLUTION\n",
    "x = \"B\"\n",
    "# PROBLEM-TEST\n",
    "x.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95e4f6b-badc-4b3d-885b-8390c8547476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELF-CHECK\n",
    "x in [\"A\", \"B\", \"C\", \"D\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5c786d-d8ce-42b0-a3a2-feac7ed4e4d4",
   "metadata": {},
   "source": [
    "### Problem 5\n",
    "Which of these statements is true?\n",
    "\n",
    "A) Interpreted code is usually faster than compiled code.  \n",
    "B) Compiling code is always the best solution for everything that you do.  \n",
    "C) Compiled code is usually faster than interpreted code.  \n",
    "D) Compiling code is never good, because the compilation time adds additional overhead.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfeb2c62-ae56-4fea-8518-3d380bdb8097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROBLEM (2)\n",
    "# store your answer as a string (A/B/C/D) in a variable named x\n",
    "# SOLUTION\n",
    "x = \"C\"\n",
    "# PROBLEM-TEST\n",
    "x.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a9fd1e-7a71-42ac-b6dc-2d5c28ea2338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELF-CHECK\n",
    "x in [\"A\", \"B\", \"C\", \"D\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a66e2bc-0414-451d-ad12-90e73e15cfb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 (PHYSnet)",
   "language": "python",
   "name": "physnet_3_9_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
